{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought this was a cool implementation to work on as it is one of the tests that differentiate between an AI(Artificial Intelligence) and a human being.\n",
    "\n",
    "Stemming can be looked as taking a certain and attempting to find its \"root\" word in the English word. Let's test it out! Shall we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "word = \"investing\" #This is the word I will try to stem the root word from\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's kind of cool to see how cool a computer can really be! I imported a stemmer and to test, i fed it the word \"investing\". In the english, as a human, the root word is \"invest\"! Guess what is ouputted!\n",
    "\n",
    "\n",
    "The reason why I used to PorterStemmer as it is one example of an implementation of a stemmer. It is not as rigorious but it does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invest'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"investing\" #This is the word I will try to stem the root word from\n",
    "ps.stem(word)\n",
    "\n",
    "#Using investing as the test word, the right answer should be \"invest\"\n",
    "#And now to test it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to use the Lancaster Stemmer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : giv\n",
      "giver : giv\n",
      "giving : giv\n",
      "given : giv\n"
     ]
    }
   ],
   "source": [
    "stem_words = [\"give\", \"giver\", \"giving\", \"given\"]\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "for words in stem_words:\n",
    "    print(words + \" : \" + ls.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is quite interesting....in the previous PorterStemmer, it took a string that is a word and attempted to find the root word correctly which it did. \n",
    "\n",
    "The output of the Lancaster Stemmer shows me that is quite more aggressive. This is one of the problems of stemming as it is an implementation as there are limits to these algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
